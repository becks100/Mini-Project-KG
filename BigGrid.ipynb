{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Mini-Project  -  Foundations of Knowledge Graphs</center></h1>\n",
    "<h2><center>Trial Notebook</center></h2>\n",
    "<h3><center>Knowledge Group LRJ</center></h3>\n",
    "<center><b>Team members (IMT user name):</b></center>\n",
    "   <center>Jonas Thorben Becker (becks100)</center>\n",
    "   <center>Lukas Kneilmann (lukn)</center>\n",
    "   <center>Rupesh Sapkota (rupezzz) (now deregistered)</center>\n",
    "<br>\n",
    "<br>\n",
    "This Jupyter notebook was used to evaluate different combinations of samplers and classifiers for the learning problems in 'kg-mini-project-train_v2.ttl'. \n",
    "The knowledge gained here was then transferred to the grading task in the Jupyter notebook <font color='blue'>'grading_classification'</font>.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "import rdflib\n",
    "from owlready2 import *\n",
    "from owlrl import *\n",
    "import numpy as np\n",
    "import gensim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE \n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.combine import SMOTETomek \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- Parses the graph in the file <font color='blue'>kg-mini-project-grading.ttl</font> and saves it as <font color='blue'>g</font>\n",
    "- loads the Word2vec (?) Embedding and saves it as a <font color='blue'>model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph()\n",
    "g.parse('kg-mini-project-train_v2.ttl', format='n3')\n",
    "\n",
    "# Load pre-trained OWL2Vec* model.\n",
    "owl2vec_model = gensim.models.Word2Vec.load(\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "Function <font color='blue'>data</font>:  \n",
    "\n",
    "- for the learning problem specified by parameter <font color='blue'>i</font>: \n",
    "    - returns the training data set (<font color='blue'>y_np, X_np</font>) : \n",
    "        - creates <font color='blue'>y_np</font> by determining the class of the individuals of the learning problem\n",
    "        - creates <font color='blue'>x_np</font> by embedding the individuals using <font color='blue'>owl2vec_model</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data (i):\n",
    "    lp = rdflib.Graph()\n",
    "    lp_object_str = []\n",
    "    lp_y = []\n",
    "    \n",
    "    # tag individual with class id\n",
    "    s = 'https://lpbenchgen.org/resource/lp_' + str(i)\n",
    "    print(s)\n",
    "    for i, (s,p,o) in enumerate(g.triples((rdflib.term.URIRef(s), None, None))): \n",
    "         if str(o)=='https://lpbenchgen.org/class/LearningProblem':\n",
    "            pass\n",
    "         else:\n",
    "            lp_object_str.append(str(o))\n",
    "            if str(p) == 'https://lpbenchgen.org/property/excludesResource':\n",
    "                 lp_y.append(0)\n",
    "            else:\n",
    "                    lp_y.append(1) \n",
    "\n",
    "    # embed individuals                \n",
    "    lp_emb = []\n",
    "    for i in range(len(lp_object_str)):\n",
    "        lp_emb.append(owl2vec_model.wv[lp_object_str[i]])\n",
    "    \n",
    "    #to numpy\n",
    "    X_np = np.array(lp_emb)\n",
    "    y_np = np.array(lp_y)\n",
    "    return X_np, y_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- Evaluates the combination of different sampling methods with an exhaustive grid search over different hyperparameters in connection with cross validation for a given model for each individual learning problem in graph <font color='blue'>g</font>\n",
    "\n",
    "- Saves the best sampling method and the best hyperparameters (based on the F1-score) for each learning problem.\n",
    "\n",
    "- Due to the  train test split, this combination can then be tested on unseen data and the results are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://lpbenchgen.org/resource/lp_1\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9985913135396565\n",
      "{'C': 1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6670\n",
      "           1       0.55      0.55      0.55        42\n",
      "\n",
      "    accuracy                           0.99      6712\n",
      "   macro avg       0.77      0.77      0.77      6712\n",
      "weighted avg       0.99      0.99      0.99      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_2\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9995933103523722\n",
      "{'C': 1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6664\n",
      "           1       0.90      0.98      0.94        48\n",
      "\n",
      "    accuracy                           1.00      6712\n",
      "   macro avg       0.95      0.99      0.97      6712\n",
      "weighted avg       1.00      1.00      1.00      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_3\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9573717446652941\n",
      "{'C': 1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97      6555\n",
      "           1       0.22      0.64      0.33       157\n",
      "\n",
      "    accuracy                           0.94      6712\n",
      "   macro avg       0.60      0.79      0.65      6712\n",
      "weighted avg       0.97      0.94      0.95      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_4\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9984345297761953\n",
      "{'C': 1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6706\n",
      "           1       0.18      0.33      0.24         6\n",
      "\n",
      "    accuracy                           1.00      6712\n",
      "   macro avg       0.59      0.67      0.62      6712\n",
      "weighted avg       1.00      1.00      1.00      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_5\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9340408696304247\n",
      "{'C': 1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      6489\n",
      "           1       0.24      0.75      0.36       223\n",
      "\n",
      "    accuracy                           0.91      6712\n",
      "   macro avg       0.61      0.83      0.66      6712\n",
      "weighted avg       0.97      0.91      0.93      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_6\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9995497875115958\n",
      "{'C': 1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6659\n",
      "           1       0.93      0.98      0.95        53\n",
      "\n",
      "    accuracy                           1.00      6712\n",
      "   macro avg       0.96      0.99      0.98      6712\n",
      "weighted avg       1.00      1.00      1.00      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_7\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.999709973681124\n",
      "{'C': 0.1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6647\n",
      "           1       0.95      0.97      0.96        65\n",
      "\n",
      "    accuracy                           1.00      6712\n",
      "   macro avg       0.98      0.98      0.98      6712\n",
      "weighted avg       1.00      1.00      1.00      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_8\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.998719518300154\n",
      "{'C': 1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6679\n",
      "           1       0.60      0.73      0.66        33\n",
      "\n",
      "    accuracy                           1.00      6712\n",
      "   macro avg       0.80      0.86      0.83      6712\n",
      "weighted avg       1.00      1.00      1.00      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_9\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9987826262192554\n",
      "{'C': 1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6687\n",
      "           1       0.55      0.64      0.59        25\n",
      "\n",
      "    accuracy                           1.00      6712\n",
      "   macro avg       0.78      0.82      0.80      6712\n",
      "weighted avg       1.00      1.00      1.00      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_10\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9532063317744018\n",
      "{'C': 1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      6622\n",
      "           1       0.16      0.64      0.26        90\n",
      "\n",
      "    accuracy                           0.95      6712\n",
      "   macro avg       0.58      0.80      0.62      6712\n",
      "weighted avg       0.98      0.95      0.96      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_11\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9991873626238126\n",
      "{'C': 1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6682\n",
      "           1       0.89      0.83      0.86        30\n",
      "\n",
      "    accuracy                           1.00      6712\n",
      "   macro avg       0.95      0.92      0.93      6712\n",
      "weighted avg       1.00      1.00      1.00      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_12\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9856952242048012\n",
      "{'C': 1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      6672\n",
      "           1       0.11      0.33      0.17        40\n",
      "\n",
      "    accuracy                           0.98      6712\n",
      "   macro avg       0.55      0.65      0.58      6712\n",
      "weighted avg       0.99      0.98      0.99      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_13\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9992463598182815\n",
      "{'C': 0.1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6707\n",
      "           1       0.33      0.20      0.25         5\n",
      "\n",
      "    accuracy                           1.00      6712\n",
      "   macro avg       0.67      0.60      0.62      6712\n",
      "weighted avg       1.00      1.00      1.00      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_14\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9974499447660203\n",
      "{'C': 1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6698\n",
      "           1       0.35      0.43      0.39        14\n",
      "\n",
      "    accuracy                           1.00      6712\n",
      "   macro avg       0.68      0.71      0.69      6712\n",
      "weighted avg       1.00      1.00      1.00      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_15\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:1.0\n",
      "{'C': 0.1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6593\n",
      "           1       0.98      1.00      0.99       119\n",
      "\n",
      "    accuracy                           1.00      6712\n",
      "   macro avg       0.99      1.00      1.00      6712\n",
      "weighted avg       1.00      1.00      1.00      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_16\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.999128429187125\n",
      "{'C': 0.5} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6712\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00      6712\n",
      "   macro avg       0.50      0.50      0.50      6712\n",
      "weighted avg       1.00      1.00      1.00      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:1.0\n",
      "{'C': 0.1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5661\n",
      "           1       1.00      1.00      1.00      1051\n",
      "\n",
      "    accuracy                           1.00      6712\n",
      "   macro avg       1.00      1.00      1.00      6712\n",
      "weighted avg       1.00      1.00      1.00      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_18\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9993642321240266\n",
      "{'C': 0.5} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6614\n",
      "           1       0.96      1.00      0.98        98\n",
      "\n",
      "    accuracy                           1.00      6712\n",
      "   macro avg       0.98      1.00      0.99      6712\n",
      "weighted avg       1.00      1.00      1.00      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_19\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9982034513092104\n",
      "{'C': 1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6702\n",
      "           1       0.18      0.50      0.26        10\n",
      "\n",
      "    accuracy                           1.00      6712\n",
      "   macro avg       0.59      0.75      0.63      6712\n",
      "weighted avg       1.00      1.00      1.00      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_20\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9620810434794571\n",
      "{'C': 1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97      6532\n",
      "           1       0.28      0.79      0.41       180\n",
      "\n",
      "    accuracy                           0.94      6712\n",
      "   macro avg       0.64      0.87      0.69      6712\n",
      "weighted avg       0.97      0.94      0.95      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_21\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9988403435486903\n",
      "{'C': 1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6699\n",
      "           1       0.69      0.85      0.76        13\n",
      "\n",
      "    accuracy                           1.00      6712\n",
      "   macro avg       0.84      0.92      0.88      6712\n",
      "weighted avg       1.00      1.00      1.00      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_22\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9996518038234379\n",
      "{'C': 0.5} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6702\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           1.00      6712\n",
      "   macro avg       0.50      0.50      0.50      6712\n",
      "weighted avg       1.00      1.00      1.00      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_23\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9994245932997025\n",
      "{'C': 0.5} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6701\n",
      "           1       0.55      0.55      0.55        11\n",
      "\n",
      "    accuracy                           1.00      6712\n",
      "   macro avg       0.77      0.77      0.77      6712\n",
      "weighted avg       1.00      1.00      1.00      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_24\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9985931558208737\n",
      "{'C': 1} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6700\n",
      "           1       0.31      0.33      0.32        12\n",
      "\n",
      "    accuracy                           1.00      6712\n",
      "   macro avg       0.65      0.67      0.66      6712\n",
      "weighted avg       1.00      1.00      1.00      6712\n",
      "\n",
      "\n",
      "https://lpbenchgen.org/resource/lp_25\n",
      "(15660, 300)\n",
      "SVMSMOTE(n_jobs=-1, random_state=42) sampling done, score:0.9976651715229604\n",
      "{'C': 0.5} SVMSMOTE(n_jobs=-1, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6689\n",
      "           1       0.33      0.57      0.41        23\n",
      "\n",
      "    accuracy                           0.99      6712\n",
      "   macro avg       0.66      0.78      0.70      6712\n",
      "weighted avg       1.00      0.99      1.00      6712\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "l = []\n",
    "modellist = []\n",
    "creports =[]\n",
    "smplist = []\n",
    "\n",
    "best_clf = None\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "smsvm = SVMSMOTE(random_state=42,n_jobs=-1)\n",
    "sm = SMOTE(random_state=42)\n",
    "smote_enn = SMOTEENN(random_state=0,n_jobs=-1)   # perhaps different resampling because its slow \n",
    "smt = SMOTETomek(random_state=42,n_jobs=-1)\n",
    "ada = ADASYN(random_state=42)\n",
    "\n",
    "#sampler =[ros,smsvm,sm,smote_enn,smt,ada]\n",
    "sampler =[smsvm]\n",
    "\n",
    "for i in range(1,26):\n",
    "    # create X,Y\n",
    "    X_np,y_np = data(i)\n",
    "    \n",
    "\n",
    "    # train test split & resample\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_np, y_np, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Standardize and resample\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train) # for svm\n",
    "    X_test = scaler.transform(X_test) \n",
    "    \n",
    "    best_score =0\n",
    "    best_smp =''\n",
    "    \n",
    "    for smp in sampler:\n",
    "        \n",
    "        try: \n",
    "            X_train_re, y_train_re = smp.fit_resample(X_train, y_train)  \n",
    "            \n",
    "            print(X_train.shape)\n",
    "\n",
    "            parameters = { 'C':[0.1,0.5,1]}  \n",
    "            m= LinearSVC(dual=False, penalty='l2',max_iter=2000) # insert various models\n",
    "\n",
    "            clf = GridSearchCV(m, parameters,verbose=0,n_jobs=-1, scoring = {'precision_macro','f1', 'accuracy', 'recall','roc_auc'}, refit='f1')  \n",
    "            clf.fit(X_train_re, y_train_re)\n",
    "            print( str(smp) + ' sampling done, score:'+ str(clf.best_score_))\n",
    "        \n",
    "            if clf.best_score_ > best_score:\n",
    "                best_score = clf.best_score_\n",
    "                best_clf = clf\n",
    "                best_smp = str(smp)\n",
    "                \n",
    "        except:\n",
    "            print(str(smp)+ ': An exception occurred')\n",
    "            \n",
    "            X_train_re, y_train_re = smote_enn.fit_resample(X_train, y_train)  \n",
    "\n",
    "            parameters = { 'C':[0.1,0.5,1]}  \n",
    "            m= LinearSVC(dual=False, penalty='l2',max_iter=2000)\n",
    "\n",
    "            clf = GridSearchCV(m, parameters,verbose=0,n_jobs=-1, scoring = {'precision_macro','f1', 'accuracy', 'recall','roc_auc'}, refit='f1')  \n",
    "            clf.fit(X_train_re, y_train_re)\n",
    "            print( 'smote sampling done, score:'+ str(clf.best_score_))\n",
    "        \n",
    "            if clf.best_score_ > best_score:\n",
    "                best_score = clf.best_score_\n",
    "                best_clf = clf\n",
    "                best_smp = 'smote_enn'\n",
    "        \n",
    "    \n",
    "    # save and print results\n",
    "    l.append(best_clf.best_params_)\n",
    "    smplist.append(best_smp)\n",
    "    print(best_clf.best_params_, best_smp)\n",
    "    print(classification_report(y_test, best_clf.predict(X_test))) #for final decision\n",
    "    print()\n",
    "    creports.append(classification_report(y_test, best_clf.predict(X_test),output_dict=True)) #for final decision\n",
    "    \n",
    "    best_score=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "In the following cells, the results are inspected and evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LinearSVC(dual=False, max_iter=2000), n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 0.5, 1]}, refit='f1',\n",
       "             scoring={'recall', 'precision_macro', 'accuracy', 'roc_auc', 'f1'})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)',\n",
       " 'SVMSMOTE(n_jobs=-1, random_state=42)']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.empty(0)#\n",
    "for i in range(0,2):\n",
    "    a = np.append(a,creports[i].get('1').get('precision'))\n",
    "a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.empty(0)#\n",
    "for i in range(0,2):\n",
    "    a = np.append(a,creports[i].get('1').get('f1-score'))\n",
    "a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.empty(0)#\n",
    "for i in range(0,2):\n",
    "    a = np.append(a,creports[i].get('macro avg').get('f1-score'))\n",
    "a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'C': 0.1},\n",
       " {'C': 0.1},\n",
       " {'C': 0.1},\n",
       " {'C': 0.1},\n",
       " {'C': 0.1},\n",
       " {'C': 1},\n",
       " {'C': 0.1},\n",
       " {'C': 0.5},\n",
       " {'C': 0.1},\n",
       " {'C': 0.1},\n",
       " {'C': 0.1},\n",
       " {'C': 0.1},\n",
       " {'C': 0.1},\n",
       " {'C': 0.1},\n",
       " {'C': 0.1},\n",
       " {'C': 0.1},\n",
       " {'C': 0.1},\n",
       " {'C': 0.5},\n",
       " {'C': 0.1},\n",
       " {'C': 0.1},\n",
       " {'C': 0.1},\n",
       " {'C': 1},\n",
       " {'C': 0.1},\n",
       " {'C': 0.1},\n",
       " {'C': 0.1}]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
